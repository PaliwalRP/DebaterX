{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "CEwezqplT-Z0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import random\n",
    "import speech_recognition as sr\n",
    "#import pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8MmM2PfxVcVn",
    "outputId": "b38453f1-6201-4b1b-c91a-1b9bf54784f9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "f=open('human_bot.txt','r',errors = 'ignore') \n",
    "raw_doc = f.read() \n",
    "raw_doc = raw_doc.lower() \n",
    "nltk.download ('punkt') \n",
    "nltk.download ('wordnet') \n",
    "sent_tokens = nltk.sent_tokenize(raw_doc) \n",
    "word_tokens = nltk.word_tokenize(raw_doc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RyEYgpCrXKzu",
    "outputId": "035dd402-2132-457f-ea62-6500773baa98"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the products of technology such as machines that have become everyday parts of our lives are no longer simple tools, but their meanings in our lives have expanded into something more complex.',\n",
       " 'the products of technology,influence and change the sense of perception and emotional state of people.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokens[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EtFs59oqdKAX",
    "outputId": "b77d9b03-c4e8-46a5-b39f-17bd19dbad87"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'products', 'of', 'technology']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokens[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mIJhnQ1ldlDb"
   },
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "_AYGdRzJdPQb"
   },
   "outputs": [],
   "source": [
    "lemmer = nltk.stem.WordNetLemmatizer()\n",
    "def LemTokens (tokens): \n",
    "  return [lemmer.lemmatize(token) for token in tokens] \n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "def LemNormalize(text): \n",
    "  return LemTokens (nltk.word_tokenize(text.lower ().translate(remove_punct_dict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uXAflgbBgU3M"
   },
   "source": [
    "# Defining the greeting message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "3udV_6xDgcqS"
   },
   "outputs": [],
   "source": [
    "GREET_INPUTS = (\"hello\", \"hii\", \"hi\", \"hey\", \"good morning\",\"morning\", \"gm\",\"whatsup\",\"hy\",\"how you doing ?\",\"How are you ?\")\n",
    "GREET_RESPONSES = [\"hii, DebaterX can see a beautifull face\",\"hey their\", \"hello there\",\"Good to see you mate, I'm DebaterX\",\"Let's have a good converstation\",\"Lets have a fruitfull debate \",\"What's on your mind ? , DebaterX is very curious !\",\"I can see you have a good idea inside you ! Tell me !, DebaterX Can't Wait !\",]\n",
    "Extra_greet=\"name\"\n",
    "res=[\"My name is DebaterX\",\"I'm DebaterX\",\"People call me DebaterX\"]\n",
    "def greet(sentence):\n",
    "    for t in sentence.split():\n",
    "        if(t==Extra_greet):\n",
    "            return random.choice(res)\n",
    "    for word in sentence.split():\n",
    "     if word.lower() in GREET_INPUTS:\n",
    "      return random.choice(GREET_RESPONSES)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d7iFRmi7iCm4"
   },
   "source": [
    "# Responce Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3ZvWx9ZTiMqi"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "8hvk3UMClbnO"
   },
   "outputs": [],
   "source": [
    "def response(user_response): \n",
    "  robo1_response=''\n",
    "  TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
    "  tfidf = TfidfVec.fit_transform(sent_tokens)\n",
    "  vals = cosine_similarity(tfidf[-1], tfidf) \n",
    "  idx = vals.argsort()[0][-2] \n",
    "  flat = vals.flatten()\n",
    "  flat.sort()\n",
    "  req_tfidf = flat[-2]\n",
    "  if (req_tfidf==0): \n",
    "    robo1_response = robo1_response+\"I am sorry! I don't understand you\" \n",
    "    return robo1_response\n",
    "  else: \n",
    "    robo1_response = robo1_response+sent_tokens[idx] \n",
    "    return robo1_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cg3olgVunXms"
   },
   "source": [
    "# defining start/end protocols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lakdUYlmnd4_",
    "outputId": "2cbda46d-2469-4972-d95b-111685d05428"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh hi ! I'm DebaterX ,I can debate on a topic you like !If you had enough of me , say bye! \n",
      "Please Enter 1 To Use Speech 1\n",
      "Silence please , calibirating background noise\n",
      "Calibirated , Please Speak....... : \n",
      "You said : hello \n",
      "DebaterX: hello there\n",
      "Silence please , calibirating background noise\n",
      "Calibirated , Please Speak....... : \n",
      "You said : bye \n",
      "DebaterX: That was a good fight indeed!I am waiting for another one ,come back as soon as you are ready!\n"
     ]
    }
   ],
   "source": [
    "flag = True\n",
    "print(\"Oh hi ! I'm DebaterX ,I can debate on a topic you like !If you had enough of me , say bye! \")\n",
    "ch=int(input(\"Please Enter 1 To Use Speech \"))\n",
    "r=sr.Recognizer()\n",
    "while(flag == True):\n",
    "    if(ch==1):\n",
    "        with sr.Microphone() as mic:\n",
    "            print(\"Silence please , calibirating background noise\")\n",
    "            r.adjust_for_ambient_noise(mic,duration=2)\n",
    "            print(\"Calibirated , Please Speak....... : \")\n",
    "            audio=r.listen(mic)\n",
    "            mytext=r.recognize_google(audio)\n",
    "            mytext=mytext.lower()\n",
    "            print(f\"You said : {mytext} \")\n",
    "            user_response = mytext\n",
    "    else:\n",
    "        user_response = input()\n",
    "        user_response = user_response.lower()\n",
    "    if (user_response != 'bye'):\n",
    "        \n",
    "        if (user_response == 'thanks' or user_response == 'thank you' or user_response == 'thanks for help' or user_response == 'cool'or user_response == 'cya'or user_response == 'good bye'or user_response == 'great'): \n",
    "            flag = False\n",
    "            bye_res1=[\"Was good taking to you !\",\"Goodbye! Take care\",\"What a great discussion!Let's have another one in a while!\",\"Awww ,why such a early good bye! Lets have another a debate about a differnt topic soon\",\"That was a good fight indeed!I am waiting for another one ,come back as soon as you are ready!\"]\n",
    "            temp1=random.choice(bye_res1)\n",
    "            print(f\"Siya: {temp1}\")\n",
    "        else:\n",
    "               \n",
    "            if (greet(user_response) != None):\n",
    "                print(\"DebaterX: \"+greet(user_response)) \n",
    "            else: \n",
    "                sent_tokens.append(user_response)\n",
    "                word_tokens = word_tokens+nltk.word_tokenize(user_response)\n",
    "                final_words = list(set(word_tokens))\n",
    "                print(\"DebaterX: \", end=\"\")\n",
    "                print(response(user_response))\n",
    "                sent_tokens.remove(user_response)\n",
    "    else:\n",
    "        flag=False \n",
    "        bye_res=[\"Was good taking to you !\",\"Goodbye! Take care\",\"What a great discussion!Let's have another one in a while!\",\"Awww ,why such a early good bye! Lets have another a debate about a differnt topic soon\",\"That was a good fight indeed!I am waiting for another one ,come back as soon as you are ready!\"]\n",
    "        temp=random.choice(bye_res)\n",
    "        print(f\"DebaterX: {temp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "debaterX_chatbot.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "fe44fef87f92f48a3a32707d0df204585f471652bc0ce87358a3ce712bc24db0"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
